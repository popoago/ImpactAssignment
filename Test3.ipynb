{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "orBhcWpDm7rM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mount google drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'impact/'\n",
        "\n",
        "#unzip data into the main folder\n",
        "!unzip -qq ./gdrive/My\\ Drive/impact/tiny-imagenet-200.zip\n",
        "\n",
        "#run the model script the initialize it\n",
        "%run ./gdrive/My\\ Drive/impact/resnet.ipynb\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.48, 0.448, 0.398], [0.276, 0.268, 0.280])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.48, 0.448, 0.398], [0.276, 0.268, 0.280])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "#read the data\n",
        "data_dir = 'tiny-imagenet-200'\n",
        "image_datasets = {x: torchvision.datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=512,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8EFW8ZspM8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#script taken from pytorch.org\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QSXK10ksGlU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4005
        },
        "outputId": "57056a12-f718-48ce-c6d2-fc53edbf1af4"
      },
      "source": [
        "model= Resnet(BasicBlock,[9,9,9])\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3,momentum=0.95)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=90)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/89\n",
            "----------\n",
            "train Loss: 4.9924 Acc: 0.0302\n",
            "val Loss: 6.1934 Acc: 0.0014\n",
            "\n",
            "Epoch 1/89\n",
            "----------\n",
            "train Loss: 4.3758 Acc: 0.0823\n",
            "val Loss: 7.5991 Acc: 0.0046\n",
            "\n",
            "Epoch 2/89\n",
            "----------\n",
            "train Loss: 3.9644 Acc: 0.1318\n",
            "val Loss: 7.8841 Acc: 0.0094\n",
            "\n",
            "Epoch 3/89\n",
            "----------\n",
            "train Loss: 3.6908 Acc: 0.1722\n",
            "val Loss: 7.4868 Acc: 0.0207\n",
            "\n",
            "Epoch 4/89\n",
            "----------\n",
            "train Loss: 3.4732 Acc: 0.2062\n",
            "val Loss: 8.4530 Acc: 0.0132\n",
            "\n",
            "Epoch 5/89\n",
            "----------\n",
            "train Loss: 3.3391 Acc: 0.2307\n",
            "val Loss: 9.7152 Acc: 0.0055\n",
            "\n",
            "Epoch 6/89\n",
            "----------\n",
            "train Loss: 3.1041 Acc: 0.2756\n",
            "val Loss: 9.5383 Acc: 0.0062\n",
            "\n",
            "Epoch 7/89\n",
            "----------\n",
            "train Loss: 3.0533 Acc: 0.2858\n",
            "val Loss: 9.5177 Acc: 0.0065\n",
            "\n",
            "Epoch 8/89\n",
            "----------\n",
            "train Loss: 3.0280 Acc: 0.2885\n",
            "val Loss: 9.6869 Acc: 0.0071\n",
            "\n",
            "Epoch 9/89\n",
            "----------\n",
            "train Loss: 3.0066 Acc: 0.2925\n",
            "val Loss: 9.8107 Acc: 0.0057\n",
            "\n",
            "Epoch 10/89\n",
            "----------\n",
            "train Loss: 2.9835 Acc: 0.2979\n",
            "val Loss: 9.8304 Acc: 0.0059\n",
            "\n",
            "Epoch 11/89\n",
            "----------\n",
            "train Loss: 2.9614 Acc: 0.3010\n",
            "val Loss: 9.9523 Acc: 0.0061\n",
            "\n",
            "Epoch 12/89\n",
            "----------\n",
            "train Loss: 2.9404 Acc: 0.3049\n",
            "val Loss: 10.0123 Acc: 0.0059\n",
            "\n",
            "Epoch 13/89\n",
            "----------\n",
            "train Loss: 2.9035 Acc: 0.3126\n",
            "val Loss: 9.9137 Acc: 0.0062\n",
            "\n",
            "Epoch 14/89\n",
            "----------\n",
            "train Loss: 2.8938 Acc: 0.3144\n",
            "val Loss: 9.9831 Acc: 0.0062\n",
            "\n",
            "Epoch 15/89\n",
            "----------\n",
            "train Loss: 2.8939 Acc: 0.3154\n",
            "val Loss: 9.9137 Acc: 0.0061\n",
            "\n",
            "Epoch 16/89\n",
            "----------\n",
            "train Loss: 2.8917 Acc: 0.3148\n",
            "val Loss: 9.9154 Acc: 0.0062\n",
            "\n",
            "Epoch 17/89\n",
            "----------\n",
            "train Loss: 2.8844 Acc: 0.3165\n",
            "val Loss: 9.9896 Acc: 0.0065\n",
            "\n",
            "Epoch 18/89\n",
            "----------\n",
            "train Loss: 2.8837 Acc: 0.3161\n",
            "val Loss: 9.9860 Acc: 0.0064\n",
            "\n",
            "Epoch 19/89\n",
            "----------\n",
            "train Loss: 2.8794 Acc: 0.3190\n",
            "val Loss: 10.0414 Acc: 0.0059\n",
            "\n",
            "Epoch 20/89\n",
            "----------\n",
            "train Loss: 2.8742 Acc: 0.3180\n",
            "val Loss: 9.9379 Acc: 0.0062\n",
            "\n",
            "Epoch 21/89\n",
            "----------\n",
            "train Loss: 2.8756 Acc: 0.3178\n",
            "val Loss: 10.0723 Acc: 0.0061\n",
            "\n",
            "Epoch 22/89\n",
            "----------\n",
            "train Loss: 2.8751 Acc: 0.3179\n",
            "val Loss: 9.9580 Acc: 0.0062\n",
            "\n",
            "Epoch 23/89\n",
            "----------\n",
            "train Loss: 2.8766 Acc: 0.3174\n",
            "val Loss: 9.9994 Acc: 0.0061\n",
            "\n",
            "Epoch 24/89\n",
            "----------\n",
            "train Loss: 2.8745 Acc: 0.3183\n",
            "val Loss: 9.9478 Acc: 0.0064\n",
            "\n",
            "Epoch 25/89\n",
            "----------\n",
            "train Loss: 2.8764 Acc: 0.3171\n",
            "val Loss: 9.9778 Acc: 0.0062\n",
            "\n",
            "Epoch 26/89\n",
            "----------\n",
            "train Loss: 2.8746 Acc: 0.3184\n",
            "val Loss: 9.9835 Acc: 0.0064\n",
            "\n",
            "Epoch 27/89\n",
            "----------\n",
            "train Loss: 2.8745 Acc: 0.3178\n",
            "val Loss: 9.9148 Acc: 0.0066\n",
            "\n",
            "Epoch 28/89\n",
            "----------\n",
            "train Loss: 2.8735 Acc: 0.3179\n",
            "val Loss: 10.0004 Acc: 0.0062\n",
            "\n",
            "Epoch 29/89\n",
            "----------\n",
            "train Loss: 2.8728 Acc: 0.3190\n",
            "val Loss: 10.0347 Acc: 0.0061\n",
            "\n",
            "Epoch 30/89\n",
            "----------\n",
            "train Loss: 2.8731 Acc: 0.3187\n",
            "val Loss: 9.9777 Acc: 0.0064\n",
            "\n",
            "Epoch 31/89\n",
            "----------\n",
            "train Loss: 2.8730 Acc: 0.3187\n",
            "val Loss: 9.9933 Acc: 0.0061\n",
            "\n",
            "Epoch 32/89\n",
            "----------\n",
            "train Loss: 2.8721 Acc: 0.3188\n",
            "val Loss: 9.9783 Acc: 0.0061\n",
            "\n",
            "Epoch 33/89\n",
            "----------\n",
            "train Loss: 2.8723 Acc: 0.3189\n",
            "val Loss: 9.9943 Acc: 0.0063\n",
            "\n",
            "Epoch 34/89\n",
            "----------\n",
            "train Loss: 2.8734 Acc: 0.3183\n",
            "val Loss: 9.9270 Acc: 0.0066\n",
            "\n",
            "Epoch 35/89\n",
            "----------\n",
            "train Loss: 2.8734 Acc: 0.3179\n",
            "val Loss: 10.0226 Acc: 0.0062\n",
            "\n",
            "Epoch 36/89\n",
            "----------\n",
            "train Loss: 2.8724 Acc: 0.3197\n",
            "val Loss: 9.9141 Acc: 0.0064\n",
            "\n",
            "Epoch 37/89\n",
            "----------\n",
            "train Loss: 2.8732 Acc: 0.3189\n",
            "val Loss: 10.0239 Acc: 0.0063\n",
            "\n",
            "Epoch 38/89\n",
            "----------\n",
            "train Loss: 2.8732 Acc: 0.3188\n",
            "val Loss: 9.9069 Acc: 0.0065\n",
            "\n",
            "Epoch 39/89\n",
            "----------\n",
            "train Loss: 2.8725 Acc: 0.3183\n",
            "val Loss: 10.0030 Acc: 0.0062\n",
            "\n",
            "Epoch 40/89\n",
            "----------\n",
            "train Loss: 2.8722 Acc: 0.3177\n",
            "val Loss: 9.9448 Acc: 0.0063\n",
            "\n",
            "Epoch 41/89\n",
            "----------\n",
            "train Loss: 2.8728 Acc: 0.3186\n",
            "val Loss: 9.9394 Acc: 0.0065\n",
            "\n",
            "Epoch 42/89\n",
            "----------\n",
            "train Loss: 2.8746 Acc: 0.3187\n",
            "val Loss: 10.0347 Acc: 0.0059\n",
            "\n",
            "Epoch 43/89\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5573be58086e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n\u001b[0;32m----> 8\u001b[0;31m                        num_epochs=90)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-77b76ce2b63b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi9dL13TtNJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        },
        "outputId": "2bfc017f-d48c-45b7-ad63-644f608e9ff4"
      },
      "source": [
        "model= Resnet(BasicBlock,[9,9,9])\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-3,momentum=0.95)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=90)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/89\n",
            "----------\n",
            "train Loss: 4.6151 Acc: 0.0616\n",
            "val Loss: 8.7488 Acc: 0.0058\n",
            "\n",
            "Epoch 1/89\n",
            "----------\n",
            "train Loss: 3.8825 Acc: 0.1451\n",
            "val Loss: 8.3639 Acc: 0.0010\n",
            "\n",
            "Epoch 2/89\n",
            "----------\n",
            "train Loss: 3.5871 Acc: 0.1883\n",
            "val Loss: 6.9114 Acc: 0.0105\n",
            "\n",
            "Epoch 3/89\n",
            "----------\n",
            "train Loss: 3.4000 Acc: 0.2205\n",
            "val Loss: 9.6476 Acc: 0.0018\n",
            "\n",
            "Epoch 4/89\n",
            "----------\n",
            "train Loss: 3.2648 Acc: 0.2437\n",
            "val Loss: 8.9131 Acc: 0.0027\n",
            "\n",
            "Epoch 5/89\n",
            "----------\n",
            "train Loss: 3.1705 Acc: 0.2641\n",
            "val Loss: 9.1635 Acc: 0.0021\n",
            "\n",
            "Epoch 6/89\n",
            "----------\n",
            "train Loss: 2.7417 Acc: 0.3479\n",
            "val Loss: 9.4266 Acc: 0.0082\n",
            "\n",
            "Epoch 7/89\n",
            "----------\n",
            "train Loss: 2.5890 Acc: 0.3773\n",
            "val Loss: 9.6004 Acc: 0.0076\n",
            "\n",
            "Epoch 8/89\n",
            "----------\n",
            "train Loss: 2.5247 Acc: 0.3900\n",
            "val Loss: 10.6592 Acc: 0.0059\n",
            "\n",
            "Epoch 9/89\n",
            "----------\n",
            "train Loss: 2.4755 Acc: 0.3970\n",
            "val Loss: 10.5283 Acc: 0.0062\n",
            "\n",
            "Epoch 10/89\n",
            "----------\n",
            "train Loss: 2.4408 Acc: 0.4051\n",
            "val Loss: 10.4277 Acc: 0.0048\n",
            "\n",
            "Epoch 11/89\n",
            "----------\n",
            "train Loss: 2.3993 Acc: 0.4126\n",
            "val Loss: 11.0244 Acc: 0.0072\n",
            "\n",
            "Epoch 12/89\n",
            "----------\n",
            "train Loss: 2.3654 Acc: 0.4212\n",
            "val Loss: 11.3612 Acc: 0.0057\n",
            "\n",
            "Epoch 13/89\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7bc0b9852811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n\u001b[0;32m----> 8\u001b[0;31m                        num_epochs=90)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-77b76ce2b63b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-dc952e448b5b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;31m#out = self.lastact(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-dc952e448b5b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m#out = self.drop(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNVENK-kJa6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4284
        },
        "outputId": "75cf4041-4aa8-4546-824f-4b3a681a5c70"
      },
      "source": [
        "model= Resnet(BasicBlock,[9,9,9])\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.05, weight_decay=1e-4)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=90)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/89\n",
            "----------\n",
            "train Loss: 7.1927 Acc: 0.0209\n",
            "val Loss: 9.4059 Acc: 0.0000\n",
            "\n",
            "Epoch 1/89\n",
            "----------\n",
            "train Loss: 4.7237 Acc: 0.0530\n",
            "val Loss: 6.7972 Acc: 0.0051\n",
            "\n",
            "Epoch 2/89\n",
            "----------\n",
            "train Loss: 4.3682 Acc: 0.0906\n",
            "val Loss: 7.9418 Acc: 0.0063\n",
            "\n",
            "Epoch 3/89\n",
            "----------\n",
            "train Loss: 4.1006 Acc: 0.1207\n",
            "val Loss: 8.6290 Acc: 0.0047\n",
            "\n",
            "Epoch 4/89\n",
            "----------\n",
            "train Loss: 3.9453 Acc: 0.1419\n",
            "val Loss: 7.3336 Acc: 0.0260\n",
            "\n",
            "Epoch 5/89\n",
            "----------\n",
            "train Loss: 3.8387 Acc: 0.1553\n",
            "val Loss: 9.1781 Acc: 0.0025\n",
            "\n",
            "Epoch 6/89\n",
            "----------\n",
            "train Loss: 3.7760 Acc: 0.1657\n",
            "val Loss: 7.8528 Acc: 0.0046\n",
            "\n",
            "Epoch 7/89\n",
            "----------\n",
            "train Loss: 3.7363 Acc: 0.1716\n",
            "val Loss: 8.8918 Acc: 0.0041\n",
            "\n",
            "Epoch 8/89\n",
            "----------\n",
            "train Loss: 3.7187 Acc: 0.1750\n",
            "val Loss: 7.7090 Acc: 0.0081\n",
            "\n",
            "Epoch 9/89\n",
            "----------\n",
            "train Loss: 3.4438 Acc: 0.2196\n",
            "val Loss: 8.7631 Acc: 0.0045\n",
            "\n",
            "Epoch 10/89\n",
            "----------\n",
            "train Loss: 3.4007 Acc: 0.2281\n",
            "val Loss: 7.9398 Acc: 0.0130\n",
            "\n",
            "Epoch 11/89\n",
            "----------\n",
            "train Loss: 3.3909 Acc: 0.2285\n",
            "val Loss: 8.7832 Acc: 0.0096\n",
            "\n",
            "Epoch 12/89\n",
            "----------\n",
            "train Loss: 3.3775 Acc: 0.2307\n",
            "val Loss: 8.4467 Acc: 0.0197\n",
            "\n",
            "Epoch 13/89\n",
            "----------\n",
            "train Loss: 3.3701 Acc: 0.2337\n",
            "val Loss: 9.7207 Acc: 0.0049\n",
            "\n",
            "Epoch 14/89\n",
            "----------\n",
            "train Loss: 3.3648 Acc: 0.2348\n",
            "val Loss: 9.6081 Acc: 0.0043\n",
            "\n",
            "Epoch 15/89\n",
            "----------\n",
            "train Loss: 3.3721 Acc: 0.2322\n",
            "val Loss: 9.7858 Acc: 0.0055\n",
            "\n",
            "Epoch 16/89\n",
            "----------\n",
            "train Loss: 3.3519 Acc: 0.2347\n",
            "val Loss: 9.4389 Acc: 0.0025\n",
            "\n",
            "Epoch 17/89\n",
            "----------\n",
            "train Loss: 3.3556 Acc: 0.2337\n",
            "val Loss: 8.5811 Acc: 0.0138\n",
            "\n",
            "Epoch 18/89\n",
            "----------\n",
            "train Loss: 3.3474 Acc: 0.2375\n",
            "val Loss: 9.5711 Acc: 0.0017\n",
            "\n",
            "Epoch 19/89\n",
            "----------\n",
            "train Loss: 3.1273 Acc: 0.2749\n",
            "val Loss: 9.4129 Acc: 0.0089\n",
            "\n",
            "Epoch 20/89\n",
            "----------\n",
            "train Loss: 3.0829 Acc: 0.2845\n",
            "val Loss: 9.0577 Acc: 0.0065\n",
            "\n",
            "Epoch 21/89\n",
            "----------\n",
            "train Loss: 3.0748 Acc: 0.2864\n",
            "val Loss: 9.7962 Acc: 0.0096\n",
            "\n",
            "Epoch 22/89\n",
            "----------\n",
            "train Loss: 3.0751 Acc: 0.2873\n",
            "val Loss: 9.4212 Acc: 0.0095\n",
            "\n",
            "Epoch 23/89\n",
            "----------\n",
            "train Loss: 3.0689 Acc: 0.2863\n",
            "val Loss: 9.7731 Acc: 0.0058\n",
            "\n",
            "Epoch 24/89\n",
            "----------\n",
            "train Loss: 3.0602 Acc: 0.2883\n",
            "val Loss: 9.0828 Acc: 0.0094\n",
            "\n",
            "Epoch 25/89\n",
            "----------\n",
            "train Loss: 3.0665 Acc: 0.2870\n",
            "val Loss: 10.2634 Acc: 0.0031\n",
            "\n",
            "Epoch 26/89\n",
            "----------\n",
            "train Loss: 3.0468 Acc: 0.2927\n",
            "val Loss: 9.4387 Acc: 0.0072\n",
            "\n",
            "Epoch 27/89\n",
            "----------\n",
            "train Loss: 3.0512 Acc: 0.2909\n",
            "val Loss: 10.4144 Acc: 0.0060\n",
            "\n",
            "Epoch 28/89\n",
            "----------\n",
            "train Loss: 3.0387 Acc: 0.2946\n",
            "val Loss: 9.7273 Acc: 0.0019\n",
            "\n",
            "Epoch 29/89\n",
            "----------\n",
            "train Loss: 2.8613 Acc: 0.3290\n",
            "val Loss: 10.1694 Acc: 0.0079\n",
            "\n",
            "Epoch 30/89\n",
            "----------\n",
            "train Loss: 2.8273 Acc: 0.3348\n",
            "val Loss: 12.0008 Acc: 0.0040\n",
            "\n",
            "Epoch 31/89\n",
            "----------\n",
            "train Loss: 2.8288 Acc: 0.3333\n",
            "val Loss: 9.8641 Acc: 0.0071\n",
            "\n",
            "Epoch 32/89\n",
            "----------\n",
            "train Loss: 2.8096 Acc: 0.3371\n",
            "val Loss: 10.2253 Acc: 0.0080\n",
            "\n",
            "Epoch 33/89\n",
            "----------\n",
            "train Loss: 2.8031 Acc: 0.3398\n",
            "val Loss: 9.8433 Acc: 0.0112\n",
            "\n",
            "Epoch 34/89\n",
            "----------\n",
            "train Loss: 2.8004 Acc: 0.3394\n",
            "val Loss: 9.6410 Acc: 0.0112\n",
            "\n",
            "Epoch 35/89\n",
            "----------\n",
            "train Loss: 2.7980 Acc: 0.3387\n",
            "val Loss: 10.0932 Acc: 0.0081\n",
            "\n",
            "Epoch 36/89\n",
            "----------\n",
            "train Loss: 2.7881 Acc: 0.3423\n",
            "val Loss: 11.4956 Acc: 0.0073\n",
            "\n",
            "Epoch 37/89\n",
            "----------\n",
            "train Loss: 2.7809 Acc: 0.3421\n",
            "val Loss: 10.8306 Acc: 0.0044\n",
            "\n",
            "Epoch 38/89\n",
            "----------\n",
            "train Loss: 2.7751 Acc: 0.3446\n",
            "val Loss: 10.0547 Acc: 0.0058\n",
            "\n",
            "Epoch 39/89\n",
            "----------\n",
            "train Loss: 2.6539 Acc: 0.3679\n",
            "val Loss: 10.4287 Acc: 0.0089\n",
            "\n",
            "Epoch 40/89\n",
            "----------\n",
            "train Loss: 2.6327 Acc: 0.3738\n",
            "val Loss: 11.0187 Acc: 0.0080\n",
            "\n",
            "Epoch 41/89\n",
            "----------\n",
            "train Loss: 2.6231 Acc: 0.3748\n",
            "val Loss: 11.5197 Acc: 0.0054\n",
            "\n",
            "Epoch 42/89\n",
            "----------\n",
            "train Loss: 2.6132 Acc: 0.3780\n",
            "val Loss: 11.3102 Acc: 0.0065\n",
            "\n",
            "Epoch 43/89\n",
            "----------\n",
            "train Loss: 2.6089 Acc: 0.3765\n",
            "val Loss: 11.0677 Acc: 0.0066\n",
            "\n",
            "Epoch 44/89\n",
            "----------\n",
            "train Loss: 2.6031 Acc: 0.3770\n",
            "val Loss: 10.4883 Acc: 0.0060\n",
            "\n",
            "Epoch 45/89\n",
            "----------\n",
            "train Loss: 2.6035 Acc: 0.3782\n",
            "val Loss: 10.8517 Acc: 0.0079\n",
            "\n",
            "Epoch 46/89\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d710caa4581f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n\u001b[0;32m----> 8\u001b[0;31m                        num_epochs=90)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-77b76ce2b63b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzY_I4uvRK-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}